{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Diabetic_Retinopathy_Keras_Tuner.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "8VsHUf8socjh",
        "4XQpDim8od8W"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Kushagratandon12/Diabetic_retinopathy/blob/main/Diabetic_Retinopathy_Training.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Xz5p807dVF4"
      },
      "source": [
        "# %%capture\n",
        "!pip install -q -U keras-tuner\n",
        "!rm -rf /content/sample_data\n",
        "# !mkdir -p ~/.kaggle\n",
        "# !cp kaggle.json ~/.kaggle/\n",
        "# !chmod 600 ~/.kaggle/kaggle.json"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WxAzWmaLASuA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6c663b3e-af71-419c-c5cc-6eedb38a491e"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aNGXjCRRnOGp"
      },
      "source": [
        "# Downloading The Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mRJJXYi4movj"
      },
      "source": [
        "%%capture\n",
        "# !kaggle datasets download -d kushagratandon12/diabetic-retinopathy-processed-data\n",
        "!unzip /content/drive/MyDrive/Diabetic_Balanced_Data.zip\n",
        "!rm -rf /content/diabetic-retinopathy-processed-data.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TtrxJRbKKg9e"
      },
      "source": [
        "import os \n",
        "import gc\n",
        "import cv2\n",
        "import glob\n",
        "import random\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from os import path\n",
        "from tqdm import tqdm\n",
        "import seaborn as sns\n",
        "import tensorflow as tf\n",
        "from google.colab import drive\n",
        "from google.colab import files\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.optimizers import Adam , SGD , RMSprop\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau \n",
        "from tensorflow.keras.applications.vgg16 import VGG16\n",
        "from tensorflow.keras.applications.resnet_v2 import ResNet50V2\n",
        "from tensorflow.keras.applications.inception_v3 import InceptionV3"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9IiHCTiOUJQR"
      },
      "source": [
        "def show_data(path_dataset):\n",
        "  images_data = glob.glob(path_dataset)\n",
        "  random.shuffle(images_data)\n",
        "  plt.figure(figsize=(10,10))\n",
        "  for i in range(9):\n",
        "    plt.subplot(3,3,i+1)\n",
        "    img = plt.imread(images_data[i-1])\n",
        "    plt.imshow(img)\n",
        "\n",
        "def plot_data(dataset):\n",
        "  print('Total Number Of Images {}'.format(len(dataset)))\n",
        "  img_files = [os.path.basename(name) for name in dataset]\n",
        "  data_label = [str(name.split('/')[-2]) for name in dataset]\n",
        "  df = pd.DataFrame({'filename':img_files,'label':data_label})\n",
        "  sns.countplot(df['label'])\n",
        "  df['label'].value_counts()\n",
        "  return df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JjlgbSgPlvmu"
      },
      "source": [
        "# dataset = glob.glob('/content/content/processed_data/*/*.jpeg')\n",
        "# df = plot_data(dataset)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WNIA-z-VebFd"
      },
      "source": [
        "classes=['No_Dr','Mild','Moderate','severe','Proliferative DR']\n",
        "class_dict = {}\n",
        "for i,label in enumerate(classes):\n",
        "  class_dict[i]=label\n",
        "print(class_dict)\n",
        "\n",
        "# label_1 = glob.glob('/content/processed_data/4/*.jpeg')\n",
        "# label_1 = list(label_1[10000::])\n",
        "# print(len(label_1))\n",
        "# for i in range(len(label_1)):\n",
        "#   os.remove(label_1[i])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Skk99m4mfUah"
      },
      "source": [
        "Plot Images In A Directory -> Function"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8VsHUf8socjh"
      },
      "source": [
        "## Image Aug using IMAGAUG "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sm1DSjG1qrOI"
      },
      "source": [
        "dataset = glob.glob('/content/processed_data/*/*.jpeg')\n",
        "print('Total Number Of Images {}'.format(len(dataset)))\n",
        "img_files = [os.path.basename(name) for name in dataset]\n",
        "data_label = [int(name.split('/')[-2]) for name in dataset]\n",
        "\n",
        "df = pd.DataFrame({'filename':img_files,'label':data_label})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_bj9UTSIt_Eu"
      },
      "source": [
        "df_minor = df.loc[(df['label'] !=0) & (df['label'] !=2) & (df['label'] !=1) ]\n",
        "# df_minor.head()\n",
        "\n",
        "minor_imgs =[]\n",
        "for iter,row in df_minor.iterrows():\n",
        "    fname = os.path.join(os.path.join('/content/processed_data',str(row.label)),\n",
        "                         row.filename)\n",
        "    minor_imgs.append(fname)\n",
        "print(len(minor_imgs))\n",
        "gc.collect()\n",
        "\n",
        "diabetic_imgs= minor_imgs\n",
        "diabetic_imgs = np.asarray(diabetic_imgs)\n",
        "np.random.shuffle(diabetic_imgs)\n",
        "print(diabetic_imgs.shape)\n",
        "\n",
        "\n",
        "from google.colab.patches import cv2_imshow\n",
        "plt.figure(figsize=(10, 10))\n",
        "\n",
        "\n",
        "def decode_img(filename,shape=(512,512)):\n",
        "    img = image.load_img(filename,target_size=(shape))\n",
        "    img  = image.img_to_array(img)\n",
        "    img = np.expand_dims(img,axis=0)\n",
        "    print(img.shape)\n",
        "    return img\n",
        "\n",
        "data_augmentation = tf.keras.Sequential([\n",
        "     layers.experimental.preprocessing.RandomRotation((0.1,0.3),fill_mode='nearest'),\n",
        "      layers.experimental.preprocessing.RandomZoom(0.2),\n",
        "      layers.experimental.preprocessing.RandomContrast(0.2)])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kPKEEbyGV8My"
      },
      "source": [
        "import imageio\n",
        "import warnings\n",
        "from imgaug import augmenters as iaa\n",
        "from google.colab.patches import cv2_imshow\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "plt.figure(figsize=(10, 10))\n",
        "\n",
        "seq = iaa.Sequential([\n",
        "    \t\tiaa.Crop(px=(0, 16)),\n",
        "    \t\tiaa.Fliplr(0.5),\n",
        "            iaa.Affine(rotate=(-25,25)),\n",
        "            iaa.LinearContrast(alpha=1.2),\n",
        "            iaa.GaussianBlur(sigma=1.5)\n",
        "    \t\t])\n",
        "\n",
        "def read_img(filename,shape=(512,512)):\n",
        "    img = image.load_img(filename,target_size=(shape))\n",
        "    img  = image.img_to_array(img)\n",
        "    return img\n",
        "\n",
        "def load_batch(img_list,batch=32,count=0):\n",
        "    imgs = [] \n",
        "    fnames  = []\n",
        "    i = count*batch\n",
        "    for filename in img_list[i:batch*(count+1)]:\n",
        "        img = read_img(filename)\n",
        "        imgs.append(img)\n",
        "        fnames.append(filename)\n",
        "    return imgs,fnames\n",
        "\n",
        "nb_batches  =  len(diabetic_imgs)//32\n",
        "# print(nb_batches)\n",
        "\n",
        "for idx in tqdm(range(nb_batches),position=0):\n",
        "    images,fnames = load_batch(diabetic_imgs,count=idx)\n",
        "    images_aug = seq(images=images)\n",
        "    for im, im_aug in enumerate(images_aug):\n",
        "        name = fnames[im][:-4]+'_aug_'+str(im)+'.jpeg'\n",
        "        imageio.imwrite(name, im_aug)\n",
        "\n",
        "gc.collect()\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CeHCbP2Fac9I"
      },
      "source": [
        "***Spliting Dataset***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kKJn_i4mafLR"
      },
      "source": [
        "input_data = '/content/processed_data'\n",
        "output_data = '/content/Diabetic_Balanced_Data'\n",
        "! mkdir /content/Diabetic_Balanced_Data\n",
        "if len(os.listdir(output_data))==0:\n",
        "  splitfolders.ratio(input_data, output=output_data,seed=100, ratio=(.7, .2, .1), group_prefix=None)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4P-Fn8ylyZLL"
      },
      "source": [
        "# !zip -r /content/Diabetic_Balanced_Data.zip /content/\n",
        "!mv /content/Diabetic_Balanced_Data.zip /content/drive/MyDrive/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X7EuBMcKC0Oj"
      },
      "source": [
        "#Model Creation\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cs05sc2ACf7f"
      },
      "source": [
        "#Hyper-Parameter Declarations \n",
        "IMG_WIDTH = 256\n",
        "IMG_HEIGHT = 256\n",
        "IMG_SHAPE=(IMG_WIDTH,IMG_HEIGHT)\n",
        "test_data = '/content/content/Diabetic_Balanced_Data/test'\n",
        "training_data = '/content/content/Diabetic_Balanced_Data/train'\n",
        "validation_data = '/content/content/Diabetic_Balanced_Data/val'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K3JR6z_5GVjQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9acab537-aaa1-4f37-f2a7-2d31dedb4fb9"
      },
      "source": [
        "image_data_generator = tf.keras.preprocessing.image.ImageDataGenerator(\n",
        "  rescale = 1.0/255.0,\n",
        "  )\n",
        "\n",
        "training_datagen = image_data_generator.flow_from_directory(\n",
        "    training_data,\n",
        "    target_size=IMG_SHAPE,\n",
        "    shuffle=True,\n",
        ")\n",
        "\n",
        "validation_datagen = image_data_generator.flow_from_directory(\n",
        "    validation_data,\n",
        "    target_size=IMG_SHAPE,\n",
        "    shuffle = True\n",
        ")\n",
        "\n",
        "test_datagen = image_data_generator.flow_from_directory(\n",
        "    test_data,\n",
        "    target_size=IMG_SHAPE,\n",
        "    shuffle=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 34792 images belonging to 5 classes.\n",
            "Found 9940 images belonging to 5 classes.\n",
            "Found 4971 images belonging to 5 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4XQpDim8od8W"
      },
      "source": [
        "# KERAS HYPERTUNER\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h4GRCmRoGFo5"
      },
      "source": [
        "# !rm -rf /content/drive/MyDrive/Diabetic_Hypertuner"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XEQga0_xohg8"
      },
      "source": [
        "import kerastuner as kt\n",
        "import tensorflow\n",
        "from tensorflow import keras\n",
        "def model_builder(hp):\n",
        "  model_type = hp.Choice('model_type',['ResNet50V2'])\n",
        "\n",
        "  if model_type == 'ResNet50V2':\n",
        "    base_model = ResNet50V2(input_shape=(IMG_WIDTH,IMG_HEIGHT,3),include_top=False,weights='imagenet')\n",
        "    head_model = base_model\n",
        "    for layers in base_model.layers[:45]:\n",
        "      layers.trainable=True\n",
        "    head_model = head_model.output\n",
        "    head_model = tf.keras.layers.GlobalMaxPooling2D()(head_model)\n",
        "    head_model = tf.keras.layers.Flatten(name=\"Flatten\")(head_model)\n",
        "    hp_units = hp.Int('units', min_value=1300, max_value=1750, step=150)\n",
        "    head_model = tf.keras.layers.Dense(hp_units,activation='relu')(head_model)\n",
        "    head_model = tf.keras.layers.Dropout(0.3)(head_model)\n",
        "    prediction_layer = tf.keras.layers.Dense(len(classes), activation='relu')(head_model)\n",
        "    model = tf.keras.Model(inputs=base_model.input,outputs=prediction_layer)\n",
        "    hp_learning_rate = hp.Choice('learning_rate', values=[1e-2, 1e-3, 1e-4])\n",
        "    model.compile(optimizer=keras.optimizers.Adam(learning_rate=hp_learning_rate),\n",
        "                loss=tf.keras.losses.categorical_crossentropy,\n",
        "                metrics=['accuracy'])\n",
        "\n",
        "  return model\n",
        "\n",
        "\n",
        "tuner = kt.Hyperband(model_builder,\n",
        "                     objective='val_accuracy',\n",
        "                     max_epochs=10,\n",
        "                     factor=5,\n",
        "                     directory='/content/drive/MyDrive/Diabetic_Hypertuner',\n",
        "                     project_name='diabetic_parameters')\n",
        "\n",
        "stop_early = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5)\n",
        "tuner.search(training_datagen, \n",
        "             epochs=5, \n",
        "             verbose=1,\n",
        "             shuffle=True,\n",
        "             validation_data=validation_datagen, \n",
        "             callbacks=[stop_early]\n",
        "             )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DxhxAVtYOgE-"
      },
      "source": [
        "best_hps=tuner.get_best_hyperparameters(num_trials=1)[0]\n",
        "print(best_hps)\n",
        "model = tuner.hypermodel.build(best_hps)\n",
        "history = model.fit(training_datagen, epochs=20,validation_data=validation_datagen)\n",
        "\n",
        "val_acc_per_epoch = history.history['val_accuracy']\n",
        "best_epoch = val_acc_per_epoch.index(max(val_acc_per_epoch)) + 1\n",
        "print('Best epoch: %d' % (best_epoch,))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9AhoBnHlrCpd"
      },
      "source": [
        "# Model "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "725vqnQpaSGF"
      },
      "source": [
        "%load_ext tensorboard\n",
        "from datetime import datetime\n",
        "import os"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "no7dKu98rAb9"
      },
      "source": [
        "def define_model(n_layers=45,BASE_MODEL='ResNet50V2'):\n",
        "    if BASE_MODEL =='ResNet50V2':\n",
        "        # Pre-trained model with MobileNetV2\n",
        "        base_model = ResNet50V2(input_shape=(IMG_WIDTH,IMG_HEIGHT,3),include_top=False,weights='imagenet')\n",
        "        head_model = base_model\n",
        "        for layers in base_model.layers[:n_layers]:\n",
        "            layers.trainable=True\n",
        "        head_model = head_model.output\n",
        "        head_model = tf.keras.layers.GlobalMaxPooling2D()(head_model)\n",
        "        head_model = tf.keras.layers.Flatten(name=\"Flatten\")(head_model)\n",
        "        head_model = tf.keras.layers.Dense(1600,activation='relu')(head_model)\n",
        "        head_model = tf.keras.layers.Dropout(0.2)(head_model)\n",
        "        prediction_layer = tf.keras.layers.Dense(len(classes), activation='softmax')(head_model)\n",
        "        model = tf.keras.Model(inputs=base_model.input,outputs=prediction_layer)\n",
        "    \n",
        "    if BASE_MODEL =='InceptionV3':\n",
        "        base_model = InceptionV3(input_shape=(IMG_WIDTH,IMG_HEIGHT,3),include_top=False,weights='imagenet')\n",
        "        head_model = base_model\n",
        "        for layers in base_model.layers[:n_layers]:\n",
        "            layers.trainable=False\n",
        "        \n",
        "        head_model = head_model.output\n",
        "        head_model = tf.keras.layers.GlobalMaxPooling2D()(head_model)\n",
        "        head_model = tf.keras.layers.Flatten(name=\"Flatten\")(head_model)\n",
        "        head_model = tf.keras.layers.Dense(1024,activation='relu')(head_model)\n",
        "        head_model = tf.keras.layers.Dropout(0.5)(head_model)\n",
        "        prediction_layer = tf.keras.layers.Dense(len(classes), activation='softmax')(head_model)\n",
        "        model = tf.keras.Model(inputs=base_model.input,outputs=prediction_layer)\n",
        "    return model\n",
        "\n",
        "# define Model \n",
        "model= define_model(BASE_MODEL='ResNet50V2')\n",
        "\n",
        "#Compilation of the model\n",
        "model.compile(\n",
        "    loss='categorical_crossentropy', \n",
        "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001), \n",
        "    metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "saPifif4Jujw"
      },
      "source": [
        "checkpoint_path = \"/content/drive/MyDrive/Custom_Weights\"\n",
        "\n",
        "cp_callback = ModelCheckpoint(\n",
        "                              filepath=checkpoint_path,\n",
        "                              save_weights_only=True,\n",
        "                              monitor='val_loss',\n",
        "                              verbose=1,\n",
        "                              save_best_only=True,mode='min')\n",
        "\n",
        "learning_rate_reduction = ReduceLROnPlateau(\n",
        "                                            monitor='val_accuracy', \n",
        "                                            patience = 2, \n",
        "                                            verbose=1,\n",
        "                                            factor=0.3,\n",
        "                                            min_lr=0.00001)\n",
        "\n",
        "logdir = \"logs/scalars/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=logdir)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JmmCC4OyKoYQ"
      },
      "source": [
        "%tensorboard --logdir logs/scalars\n",
        "history = model.fit(\n",
        "    training_datagen,\n",
        "    epochs=12,\n",
        "    steps_per_epoch=1000, \n",
        "    shuffle=True,\n",
        "    validation_data=validation_datagen,\n",
        "    callbacks=[cp_callback,learning_rate_reduction,tensorboard_callback])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dEy3CX5cWkGl"
      },
      "source": [
        "import gc\n",
        "gc.collect()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uCUNJvwgV4Hp"
      },
      "source": [
        "import tensorflow as tf\n",
        "tf.saved_model.save(model,'/content/drive/MyDrive/Diabetic_Weight')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_kp-6f5bjnbr"
      },
      "source": [
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from os.path import join\n",
        "diab_model = load_model('/content/drive/MyDrive/diab_model.h5')\n",
        "shape = (256,256)\n",
        "def decode_img(image_path,shape):\n",
        "    img = tf.keras.preprocessing.image.load_img(filename,target_size=(shape))\n",
        "    img = tf.keras.preprocessing.image.img_to_array(img) # converted to ndarray \n",
        "    img = img.astype(np.float32)/255.0\n",
        "    img = np.expand_dims(img,axis=0)\n",
        "    return img"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Rc-mqzYbzZt"
      },
      "source": [
        "!rm -rf /content/drive/MyDrive/Diabetic_Weight.h5"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i196yHcXbswI"
      },
      "source": [
        "diab_model.save('/content/drive/MyDrive/diab_model.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ohdF-bMpaxml"
      },
      "source": [
        "import tensorflow as tf\n",
        "tf.saved_model.save(diab_model,'/content/drive/MyDrive/Diabetic_Weight.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WMjp7MfBpkaq"
      },
      "source": [
        "import glob\n",
        "import random\n",
        "test_img = glob.glob('/content/content/Diabetic_Balanced_Data/test/*/*.jpeg')\n",
        "img_select = random.randint(1,len(test_img))\n",
        "\n",
        "print(test_img[img_select])\n",
        "img = plt.imread(test_img[img_select])\n",
        "plt.imshow(img,cmap = 'gray')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z_ko0omgjriV",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "293b7816-1cb9-4393-a01e-45699af8cd2e"
      },
      "source": [
        "test_data =glob.glob('/content/content/Diabetic_Balanced_Data/test/*/*.jpeg')\n",
        "print(\"Test data \",len(test_data))\n",
        "img_files = [os.path.basename(name) for name in test_data]\n",
        "test_label = [name.split('/')[-2] for name in test_data]\n",
        "test_df = pd.DataFrame({'filename':img_files,'label':test_label,})\n",
        "test_df.to_csv('test_data.csv')\n",
        "test_df\n",
        "\n",
        "\n",
        "# img_select = random.randint(1,len(test_data))\n",
        "# from google.colab import files\n",
        "# print(test_data[img_select])\n",
        "# files.download(test_data[img_select])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test data  1000\n",
            "/content/content/Diabetic_Balanced_Data/test/0/12815_left.jpeg\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_e27c4ed9-a08d-43bc-8a5d-d3d189305943\", \"12815_left.jpeg\", 85280)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5BTzcjKdk9tQ"
      },
      "source": [
        "predictions = []\n",
        "for iter,row in test_df.iterrows():\n",
        "  filename = join('/content/content/Diabetic_Balanced_Data/test/',join(row.label,row.filename))\n",
        "  img = decode_img(filename,shape)\n",
        "  pred = diab_model.predict(img)\n",
        "  y_classes = np.argmax(pred)\n",
        "  #print(y_classes)\n",
        "  predictions.append(pred)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-TPLL32FlXUd"
      },
      "source": [
        "test_df['pred_label']=predictions\n",
        "print(predictions[0])\n",
        "test_df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "903THP0ImaJw"
      },
      "source": [
        "y_test = test_df['label'].astype(int)\n",
        "y_pred = test_df['pred_label']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c56BS8bOon4z"
      },
      "source": [
        "y_pred = test_df.apply(lambda row: np.argmax(list(row['pred_label'])) , axis=1)\n",
        "print(y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CPI9My4Soo10"
      },
      "source": [
        "import itertools\n",
        "from sklearn.metrics import classification_report,confusion_matrix,accuracy_score\n",
        "print(classification_report(y_test, y_pred))\n",
        "cnf_matrix = confusion_matrix(y_test,y_pred)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5SwrRTd9sNxg"
      },
      "source": [
        "def plot_confusion_matrix(cm, classes, title='Confusion matrix', cmap=plt.cm.Blues):\n",
        "    cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "    plt.figure(figsize=(10,10))\n",
        "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
        "    plt.title(title)\n",
        "    plt.colorbar()\n",
        "    tick_marks = np.arange(len(classes))\n",
        "    plt.xticks(tick_marks, classes, rotation=45)\n",
        "    plt.yticks(tick_marks, classes)\n",
        "\n",
        "    fmt = '.2f'\n",
        "    thresh = cm.max() / 2.\n",
        "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
        "        plt.text(j, i, format(cm[i, j], fmt),\n",
        "                 horizontalalignment=\"center\",\n",
        "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "\n",
        "    plt.ylabel('True label')\n",
        "    plt.xlabel('Predicted label')\n",
        "    plt.tight_layout()\n",
        "\n",
        "np.set_printoptions(precision=2)\n",
        "\n",
        "\n",
        "# plot normalized confusion matrix\n",
        "plt.figure()\n",
        "plot_confusion_matrix(cnf_matrix, classes=classes, title='Normalized confusion matrix')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hUt2upa5dKP1"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}